{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCT GPT Experiment Workbench\n",
    "The aim of this notebook is to provide researchers an experiment workbench to finetune and optimise LLM prompts and to evaluate their performance on a set of examples. For this project the LLM (default: OpenAI GPT-3.5) objective is to detect and to identify the sequencing types of combination of passages (clauses). The researcher can use this notebook to optimise LLM response, which is generated based on the following three components (see `Schema and Input data` below):\n",
    "- LCT definitions (editable): optimised by researcher in LCT definition file (example file: `sequencing_types.xlsx`).\n",
    "- LCT examples with LCT classes, linkage words and reasoning (editable): examples can be removed, added, or edited by reseacher in example file (example file: `sequencing_examples_2clauses.xlsx`).\n",
    "- Prompt parsing instuctions (partially editable): Can be optimised, but should be taken with care since correct output parsing instructions are crucial to extract results (file: `instruction_prompt.txt`).\n",
    "\n",
    "The files are stored in the folder `schemas`. You can find this folder in the parent folder of this notebook. If you edit these files it is recommended to make a copy of the example file first, and to give it a unique name for version control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not required if you are running this notebook on Binder. If you run this notebook locally or on your own host environment (e.g. Colab, JupyterLab), you need to install the Python dependencies first (recommend to setup a virtual Python environment first). To install the dependencies, uncomment and run the commands in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Sydney-Informatics-Hub/LCT_sequencing\n",
    "# %cd LCT_sequencing\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies\n",
    "\n",
    "This assumes you have a copy of the repo in your parent directory including the folder \"tools\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add package libraries in folder tools\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from llm.load_schema_json import load_json, validate_json, json_to_dataframe\n",
    "from llm.utils_llm import LLM, openai_apikey_input\n",
    "from llm.excel_json_converter import excel_to_json\n",
    "\n",
    "#to open notebook in interactive mode, uncomment following line\n",
    "#init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema and Input data\n",
    "\n",
    "Define locations of files for sequencing types, instruction prompts, and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to output folder (if not existing, it will be created)\n",
    "outpath = \"./results/\"\n",
    "\n",
    "# Path to schemas and excel files for definitions and examples:\n",
    "path_schema = \"../schemas/\"\n",
    "\n",
    "# Filename for examples (.json or .xlsx), assume to be in folder path_schema:\n",
    "filename_examples = \"sequencing_examples_2clauses.xlsx\"\n",
    "\n",
    "# Filename for sequencing definitions (.json or .xlsx), assumed to be in folder path_schema:\n",
    "filename_definitions = \"sequencing_types.xlsx\"\n",
    "\n",
    "# if you want to select manually examples from the example table (filename_examples), select indices here as list\n",
    "# Ideally you want to select at least one example per sequencing type.\n",
    "# Note that indices count start with 0, not the excel row number, e.g.:\n",
    "# list_prompt_indices = [0,1,7,14,23,26,30,33]\n",
    "# Alternatively set None or empty list. In this case a random selection of examples will be used\n",
    "list_prompt_indices = None\n",
    "\n",
    "# Filename for prompt instructions\n",
    "filename_zero_prompt = \"instruction_prompt.txt\"\n",
    "\n",
    "# Filename for json schema valdiation ()\n",
    "filename_schema = \"schema_sequencing_examples_reason.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Authentication\n",
    "\n",
    "Authentication with your OpenAI API key for GPT usage (default model: GPT-3.5).\n",
    "Note that this will incur charges on your OpenAI account.\n",
    "The widget below allows you to enter your password string using an obfuscated text input box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_apikey_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment pipeline\n",
    "\n",
    "The experiment pipeline includes the following main steps:\n",
    "- load examples and LCt type definitions from files\n",
    "- split examples in prompt and test samples\n",
    "- generate prompt string from LCT type definitions and prompt examples\n",
    "- call OpenAI API for completion of prompt for each test sample\n",
    "- save prompt and response to file for each sample\n",
    "- save combined results to csv file\n",
    "- evaluate results and save evaluation metrics to file\n",
    "\n",
    "All output files are saved in the output path folder as specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llm.experiment as ex\n",
    "df_results, outpath_exp, seq_classes = ex.run_pipe(\n",
    "        outpath = outpath, \n",
    "        path_schema = path_schema, \n",
    "        filename_examples = filename_examples, \n",
    "        filename_schema = filename_schema, \n",
    "        filename_definitions = filename_definitions, \n",
    "        filename_zero_prompt = filename_zero_prompt, \n",
    "        list_prompt_indices = list_prompt_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results table for all samples\n",
    "\n",
    "The results table (see also`results_gpt-3.5-turbo-instruct.csv`) provides for each sample:\n",
    "- the string for each test sample (and additional split up in the two text clauses or chunks)\n",
    "- ground truth classification (test_class)\n",
    "- ground truth linkage word (test_linkage)\n",
    "- classification predicted by the model (pred_class)\n",
    "- probability of the predicted classification (pred_class_prob)\n",
    "- predicted linkage_word (pred_linkage)\n",
    "- filenames for prompt and response files of GPT as saved in output directory\n",
    "- number of total tokens used for each sample\n",
    "- the modelname and version\n",
    "- the GPT reasoning for the predicted class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and print results stats\n",
    "\n",
    "This will compute the confusion matrix and the evaluation metrics for the predicted classes by comparing the predicted labels (pred_class) with true labels (test_class). All results are also saved in the output folder. The following metrics are calculated based on the confusion matrix:\n",
    "- accuracy\n",
    "- recall\n",
    "- precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.eval_exp(df_results, outpath_exp, seq_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Zip result exp folder for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip via shutil\n",
    "import shutil\n",
    "import os\n",
    "shutil.make_archive(os.path.basename(outpath_exp), 'zip', base_dir = outpath_exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
